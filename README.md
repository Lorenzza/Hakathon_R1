# Hakathon_R1
[совместный хакатон Яндекс.Практикума, направления Анализа данных, и R1 Телеком.](https://www.kaggle.com/competitions/yapr1-hackaton)

Итоговая тетрадь проекта разработка модели склонности (бинарной классификации) к покупке клиентом оборудования. Хакатон командный, команда, лидером которой я была, разработала модель, предсказывающую вероятность согласия клиента на покупку дополнительного оборудования.
Особенностью проекта был датасет с числом признаков более 3 тысяч и сжатый срок выполнения - 1 неделя.
Мы провели исследовательский анализ данных, выбрали признаки для обучения моделей и сгенерировали дополнительные признаки, комбинируя зашифрованные начале и окончании названий столбцов параметры. Настроили пайплайны в grid и optuna для подбора гиперпараметров. На полученном датасете обучили модели и оценили их качество.
Лучшая модель CatBoostClassifier была проверена на тестовой выборке.
Для оценки качества был предложен коэффициент gini (основанный на метрике ROC AUC). Наш результат ROC AUC 0.6713 стал 4 из 16.
Настоящая тетрадь содержит материалы, добавленные уже после дедлайна. Метрики оказались очень чуствительны к выбору признаков. Дополнительное улучшение дала балансировка классов, корректирующая недостаточные веса позитивного класса. Итогом доработки модели стал дополнительный подъем метрики на kaggle до 0.6744. 

Стек: Python, Pandas, Seaborn, Sklearn, Pipeline, StandardScaler, Optuna, GridSearch, Feature importance, RandomForestRegressor, DecisionTreeRegressor, XGBRegressor, CatBoostRegressor, LGBMRegressor
